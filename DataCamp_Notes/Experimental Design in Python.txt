Course Description

Data is all around us and can help us to understand many things. Making a pretty graph is great, but how can we tell the difference between a few outliers on a graph and a real, reliable effect? Is a trend that we see on a graph a reliable result or just random chance playing tricks? In this course, you will learn how to interrogate datasets in a rigorous way, giving clear answers to your questions. You will learn a range of statistical tests, how to apply them, how to understand their results, and how to deal with their shortcomings. Along the way, you will explore Olympic athlete data and the differences between populations of continents.

------------------------------------------------------------------------------------------------------------------------------------

The Basics of Statistical Hypothesis Testing
FREE
0%
In this chapter, you will learn how to explore your data and ask meaningful questions. Then, you will discover how to answer these question by using your first statistical hypothesis tests: the t-test, the Chi-Square test, the Fisher exact test, and the Pearson correlation test.


Your first t-test
Now you will perform your first statistical test! We want to compare the mean heights in cm of the Sample_A group with a given value. We want to see whether the mean weight of the people in this sample is significantly different from the chosen cut-off point of 65 kg. You'll use a one-sample t-test, which allows you to compare the mean of a sample with a chosen value. You'll perform this test on the sample provided versus the crucial value of 65 kg, and test its significance by comparing the value of alpha to the p-value. scipy.stats has been loaded into the workspace as stats

Perform a one-sample t-test comparing the mean of Sample_A to 65; assign the output to t_result and print it.
Using a standard alpha value of 0.05, test the statistical significance of the result by comparing the p-value to alpha and print the appropriate message.

# Perform t-test and print result
t_result=stats.ttest_1samp(Sample_A, 65)
print(t_result)

# Test significance
alpha= 0.05
if (t_result[1] < alpha):
    print("mean value of Sample A differs from given value")
else:
	print("No significant difference found")
------------------------------------------------------------------------------------------------------------------------------------
One-sample t-test
In this exercise, you will perform a one-sample t-test using the ttest_1sample() function. Using eudata, a dataset of country-level statistics, you'll be looking at the sex ratios found in the population of European countries. You'll use a one sample t-test to determine if the mean sex ratio found among European countries differs significantly from 50-50. First, you'll make some plots, then you'll perform your test. pandas, scipy.stats, and plotnine have been loaded into the workspace as pd, stats, and p9.

Instructions 1/2
50 XP
1
2
Run the provided code, specifying the correct DataFrame, to print a density plot of Sex_ratio.
# Create the density plot
print(p9.ggplot(eudata)+ p9.aes(x='Sex_ratio')+ p9.geom_density(alpha=0.5))



Perform a one-sample t-test to see if the mean Sex_ratio of European countries is significantly different from 100. assigning the result to t_result and printing it.
Print a message regarding the statistical significance of the result.

# Create the density plot
(p9.ggplot(eudata)+ p9.aes('Sex_ratio')+ p9.geom_density(alpha=0.5))

# Perform the one-sample t-test
t_result= stats.ttest_1samp(eudata['Sex_ratio'], 100)
print(t_result)

# Test significance
alpha = 0.05
if t_result[1] < alpha:
    print("Sex ratios are significantly biased")
else:
    print("No significant bias found")
  
  ------------------------------------------------------------------------------------------------------------------------------------
  
  Two-sample t-test
Now we'll compare two sets of samples. Again, we'll be looking at the Sex_ratio found in different countries, but we're going to compare the Sex_ratio of European countries with Asian countries. Does the mean sex ratio differ between the two continents? A two-sample t-test can tell us whether the means of two samples differ significantly. The dataset is provided as euasdata. pandas, scipy.stats, and plotnine have been loaded into the workspace as pd, stats, and p9. You'll do some exploratory data analysis, then compare the groups via a statistical test.

Instructions 1/2
50 XP
1
2
Using ggplot() with geom_density(), create a density plot of Sex_ratio on the x-axis, with each Continent assigned a fill color.

# Create the density plot
print(p9.ggplot(euasdata)+ p9.aes('Sex_ratio', fill='Continent')+ p9.geom_density(alpha=0.5))

Create two arrays, Europe_Sex_ratio and Asia_Sex_ratio, containing the Sex_ratio for each continent.
Use ttest_ind() to compare Europe and Asia, assign the result to t_result, and print it.
Print the message regarding the result.

# Create the density plot
print(p9.ggplot(euasdata)+ p9.aes('Sex_ratio', fill="Continent")+ p9.geom_density(alpha=0.5))

# Create two arrays
Europe_Sex_ratio = euasdata[euasdata.Continent == "Europe"].Sex_ratio
Asia_Sex_ratio = euasdata[euasdata.Continent == "Asia"].Sex_ratio

# Perform the two-sample t-test
t_result= stats.ttest_ind(Europe_Sex_ratio, Asia_Sex_ratio)
print(t_result)

# Test significance
alpha= 0.05
if (t_result[1] < alpha):
    print("Europe and Asia have different mean sex ratios")
else: print("No significant difference found")
  
  ------------------------------------------------------------------------------------------------------------------------------------
  
  
  Chi-square test
In this exercise, you will be working with the Olympics dataset. Here, we're going to look at the sex ratio of the American Olympic squads. Is a bias present? That is to say, does the ratio of male to female athletes significantly depart from 50-50? To test this, you'll need to perform a Chi-square test on the Sex data. Data on American athletes is provided as athletes. pandas, and plotnine have been loaded into the workspace as pd and p9.

Instructions
100 XP
Using value_counts(), extract the number of individuals of each Sex from athletes, saving the result as sexratio.
Perform a chisquare() test on sexratio and print the result.
Compare the p-value to the given alpha and print the message.

# Extract sex ratio
sexratio = athletes['Sex'].value_counts()

# Perform Chi-square test
chi= stats.chisquare(sexratio)
print(chi)

# Test significance
alpha= 0.05
if chi[1] < alpha:
    print("Difference between sexes is statistically significant")
else:
    print("No significant difference between sexes found")
  
  <script.py> output:
    Power_divergenceResult(statistic=568.4776119402985, pvalue=1.2035877899749622e-125)
    Difference between sexes is statistically significant
    
    
    ------------------------------------------------------------------------------------------------------------------------------------
    Fisher's exact test
Now, you'll work with the Olympics dataset to look at the relative success of the American swimming and athletics teams. Whether each athlete received a medal is coded as True or False in the MedalTF column of athletes. Do a larger proportion of swimming or athletics participants come home with medals? A Fisher exact test is a useful way to compare proportions of samples falling into discrete categories. To test this, you'll need to perform a Fisher exact test on MedalTF in relation to Sport. pandas and plotnine have already been imported as pd and p9.

Instructions
100 XP
Using crosstab(), produce a cross-tabulation of MedalTF and Sport, saving the result as table and printing it.
Perform a fisher_exact() test on table and print the result.
Compare the p-value to the given alpha and print the message.

# Create a table of cross-tabulations
table = pd.crosstab(athletes.MedalTF, athletes.Sport)
print(table)

# Perform the Fisher exact test
fisher = stats.fisher_exact(table, alternative='two-sided')
print(fisher)

# Is the result significant?
alpha = 0.05
if fisher[1] < alpha:
    print("Proportions of medal winners differ significantly")
else:
    print("No significant difference in proportions of medal winners found")
    
    
    <script.py> output:
    Sport    Athletics  Swimming
    MedalTF                     
    False         2131       556
    True          1071      1066
    (3.8148405645231716, 2.4220956742371155e-101)
    Proportions of medal winners differ significantly
    
------------------------------------------------------------------------------------------------------------------------------------
Pearson correlation
In this exercise, you will be using the Olympic athletes dataset and focusing on just one event, the men's 100 meter running race. The dataset is provided in your workspace as athletes. You're going to be looking at how the weights of competitors have changed over time. A Pearson correlation test allows us to determine whether a linear relationship exists between two variables. pandas, scipy.stats, and plotnine have been loaded into the workspace as pd, stats, and p9, respectively. First, you'll make some plots, then you'll see how the sprinters' weights have changed over time.

Instructions 1/2
50 XP
1
2
Using geom_point(), create and print a scatter plot of Weight (y-axis) in relation to Year (x-axis), with a different color according to Event, using the athletes DataFrame.

# Create the scatter plot
print(p9.ggplot(athletes)+ p9.aes(x='Year', y='Weight', color='Event')+  p9.geom_point())


Instructions 2/2
50 XP
2
Perform a pearsonr() correlation test between athletes.Weight and athletes.Year and print the result.
Compare the p-value to the given alpha and print the message.


# Create the scatterplot
print(p9.ggplot(athletes)+ p9.aes('Year', 'Weight', color='Event')+  p9.geom_point())

# Run the correlation test
pearson = stats.pearsonr(athletes.Weight, athletes.Year)
print(pearson)

# Test if p-value is bigger or smaller than alpha
alpha = 0.05
if pearson[1] < alpha:
    print("Weights and year are significantly correlated")
else:
    print("No significant correlation found")
------------------------------------------------------------------------------------------------------------------------------------

2
Design Considerations in Experimental Design
0%
In this chapter, you will learn how to examine and multiple factors at once, controlling for the effect of confounding variables and examining interactions between variables. You will learn how to use randomization and blocking to build robust tests and how to use the powerful ANOVA method.

------------------------------------------------------------------------------------------------------------------------------------
Random sampling
In this exercise, we're going to look at random sampling. You have been provided with a large dataset (athletes) containing the details of a large number of American athletes. For the purposes of this exercise, we are interested in differences between the body Weight of competitors in swimming and athletics. In order to test this, you'll be using a two-sample t-test. However, you will be performing this test on a random sample of the data. By playing with the random subset chosen, you'll see how randomness affects our results. You will need to extract a random subset of athletes from both events in order to run your test. pandas, scipy.stats, plotnine, and random have been loaded into the workspace as pd, stats, p9, and ran, respectively.

Instructions 1/2
0 XP
1
2
Set seed to 0000.
Create two subset DataFrames (subsetathl and subsetswim) from athletes, with 30 random samples in each.
Perform a two-sample t-test on the Weight column of each subset DataFrame, save it to t_result, then print it.


# Define random seed
seed = 0000

# Create subsets
subsetathl = athletes[athletes.Sport == "Athletics"].sample(n=30, random_state= seed)
subsetswim = athletes[athletes.Sport == "Swimming"].sample(n=30, random_state= seed)

# Perform the two-sample t-test
t_result = stats.ttest_ind(subsetathl.Weight, subsetswim.Weight) 
print(t_result)

Change the seed value to 2397 and re-run the code.

# Define random seed
seed = 2397

# Create subsets
subsetathl = athletes[athletes.Sport == "Athletics"].sample(n=30, random_state= seed)
subsetswim = athletes[athletes.Sport == "Swimming"].sample(n=30, random_state= seed)

# Perform the two-sample t-test
t_result = stats.ttest_ind(subsetathl.Weight, subsetswim.Weight) 
print(t_result)




------------------------------------------------------------------------------------------------------------------------------------

Blocking
We're going to have another look at the same data but, this time, we'll use blocking to improve our approach. Like last time, you'll be using a two-sample t-test on athlete Weight within your DataFrame, athletes. This time, however, you will control for Sex as a blocking factor, sampling equally from male and female participants. You will need to extract a random subset of athletes from both events to run your test. pandas, scipy.stats, plotnine, and random have been loaded into the workspace as pd, stats, p9, and ran, respectively.

Instructions
100 XP
Create four subset DataFrames from athletes, with 15 randomly chosen samples in each, corresponding to the four possible combinations of Sex and Sport.
Concatenate the two Athletics blocks and the two Swimming blocks to create two DataFrames to compare, each containing 30 samples.
Perform a two-sample t-test on the Weight columns and print the output.

seed = 9000

# Create subset blocks
subsetathlm = athletes[(athletes.Sport == "Athletics") & (athletes.Sex == "M")].sample(n=15, random_state= seed)
subsetathlf = athletes[(athletes.Sport == "Athletics") & (athletes.Sex == "F")].sample(n=15, random_state= seed)
subsetswimm = athletes[(athletes.Sport == "Swimming") & (athletes.Sex == "M")].sample(n=15, random_state= seed)
subsetswimf = athletes[(athletes.Sport == "Swimming") & (athletes.Sex == "F")].sample(n=15, random_state= seed)

# Combine blocks
subsetathl = pd.concat([subsetathlm, subsetathlf])
subsetswim = pd.concat([subsetswimm, subsetswimf])

# Perform the two-sample t-test
print(stats.ttest_ind(subsetathl.Weight, subsetswim.Weight) )

  <script.py> output:
    Ttest_indResult(statistic=-2.9477612234116326, pvalue=0.004605461953501264)
    
    
Very good. Your t-test is significant, with a p-value under 0.05. This blocked design has resolved the issue you had in the last exercise. You can see how this type of blocking approach can be a useful way to improve your experimental design when a confounding variable is present.    

------------------------------------------------------------------------------------------------------------------------------------

Paired t-test
Think back to the potato field example that we dealt with previously. Here, you've been provided with a small DataFrame (podataframe) containing information on 10 Fields. We are interested in potato yield in tons/hectare. For each Field, we have a value for its Yield2018, before the application of a new fertilizer, and its Yield2019, after the application of the new fertilizer. You'll need to perform two t-tests, a standard two-sample test, and a paired t-test. A paired t-test will control for the variation between fields. Do the two tests give the same result? scipy.stats is loaded as stats.

Instructions 1/2
50 XP
1
Do a standard two-sample t-test, comparing 2018 and 2019 potato yield, save the result to ttestind and print it.

------------------------------------------------------------------------------------------------------------------------------------
One-way ANOVA
Let's have another look at some data from our Olympic dataset. How does the Weight of athletes vary between teams from different countries? In this exercise, you're going to use a one-way ANOVA to check for the presence of significant variation in Weight of Olympic athletes. You have been provided with the athletes DataFrame, containing details about male athletes from the Team of the United States, France, and China. Here is a set of boxplots of Weight for the athletes from those three countries.

Density plot of the body weights of Olympic athletes from three competing countries

A one-way ANOVA will allow you to see whether any differences between these groups of values are significant. pandas, scipy.stats, and plotnine have been loaded into the workspace as pd, stats, and p9, respectively.

Instructions
100 XP
Create three arrays, France_athletes, US_athletes, and China_athletes, for the athletes' Weights from each country.
Using f_oneway(), perform a one-way ANOVA on the arrays, save the result as anova, and print it.

# Create arrays
France_athletes = athletes[athletes.Team == 'France'].Weight
US_athletes = athletes[athletes.Team == 'United States'].Weight
China_athletes = athletes[athletes.Team == 'China'].Weight

# Perform one-way ANOVA
anova = stats.f_oneway(France_athletes, US_athletes, China_athletes)
print(anova)

# Create arrays
France_athletes = athletes[athletes.Team == 'France'].Weight
US_athletes = athletes[athletes.Team == 'United States'].Weight
China_athletes = athletes[athletes.Team == 'China'].Weight

# Perform one-way ANOVA
anova = stats.f_oneway(France_athletes, US_athletes, China_athletes)
print(anova)
------------------------------------------------------------------------------------------------------------------------------------
Two-way ANOVA
Let's have another look at some data from our Olympic dataset. How does the Weight of athletes vary between teams from different countries and of different sexes? In this exercise, you're going to use a two-way ANOVA to check for the presence of significant variation in the Weight of Olympic sprinters. You have been provided with the athletes DataFrame, containing details about athletes from the Team of the United States, and China, from both sexes.

Density plot of athlete weight in relation to sex and country

A two-way ANOVA will allow you to see which of these two factors, Sex and Team, have a significant effect on Weight. pandas, statsmodels, and plotnine have been loaded into the workspace as pd, sm, and p9, respectively.

Instructions
100 XP
Create a model, using the provided formula for Weight as a function of Team and Sex.
Perform a two-way ANOVA, testing for the effect of both Team and Sex on Weight, and print the ANOVA table.


# Create model
formula = 'Weight ~ Sex + Team'
model = sm.api.formula.ols(formula, data=athletes).fit()

# Perform ANOVA and print table
aov_table = sm.api.stats.anova_lm(model, typ=2)
print(aov_table)

# Create model
formula = 'Weight ~ Sex + Team'
model = sm.api.formula.ols(formula, data=athletes).fit()

# Perform ANOVA and print table
aov_table = sm.api.stats.anova_lm(model, typ=2)
print(aov_table)

Good work! According to the results of your ANOVA, Sex has a significant effect, while Team has no significant effect. ANOVA is a very powerful method, as it allows us to separate out the effects of multiple factors.

------------------------------------------------------------------------------------------------------------------------------------

wo-way ANOVA with interactive effects
Once again, you're going to look at our dataset of Olympic athletes. As in previous exercises, you'll be looking at the variation in athlete Weight. You're going to look at athletes of either Sex competing in one of two Events: the 100 meter and 10,000 meter run. Have a look at these data in the boxplots below.

Density plot of athlete weight in relation to sex and event

This dataset is provided in your workspace as athletes. An ANOVA will allow you to work out which of these variables affect Weight and whether an interactive effect is present. pandas, statsmodels, and plotnine have been loaded into the workspace as pd, sm, and p9, respectively.

Instructions
100 XP
Perform a two-way ANOVA to test whether Sex, Event, or the interaction between the two has a significant effect on Weight.
Using anova_lm() on your model, extract and print the table of results produced by your ANOVA.


# Run the ANOVA
model = sm.api.formula.ols('Weight ~ Sex + Event + Sex:Event', data = athletes).fit()

# Extract our table
aov_table = sm.api.stats.anova_lm(model, typ=2)

# Print the table
print(aov_table)

<script.py> output:
                      sum_sq      df            F        PR(>F)
    Sex        141607.485844     1.0  3191.693293  0.000000e+00
    Event       83295.483535     1.0  1877.398179  0.000000e+00
    Sex:Event    1551.609798     1.0    34.971757  3.680613e-09
    Residual   148986.100430  3358.0          NaN           NaN
    
    
Good work! Can you interpret the AOV table? Look at the p-values for the effects of Sex, Event, and Sex:Event. Using a standard alpha of 0.05, Sex, Event, and Sex:Event have a significant effect on Weight. This means that both factors influence Weight, and the effect of one factor is dependent on the other.
------------------------------------------------------------------------------------------------------------------------------------

Choosing an appropriate test
Let's look at another problem from the Olympic dataset, focusing on the Height of the competitors. Here, you've been provided with athletes data on the Norwegian and Colombian Team for each Sex. With those two factors, you'll have four separate groups. First, look at the boxplots below, then choose an appropriate statistical test.

Density plot of athlete height in relation to sex and country

Finally, carry out the test. pandas, statsmodels, and plotnine have been loaded into the workspace as pd, sm, and p9, respectively.

Create a formula and model, examining Height as a function of Sex, Team, and their interaction.
Perform a two-way ANOVA, testing for the effect of Sex, Team, and an interactive effect on Weight, and print the ANOVA table.

# Create model
formula = 'Height ~ Sex + Team + Sex:Team'
model = sm.api.formula.ols(formula, data=athletes).fit()

# Perform ANOVA and print table
aov_table = sm.api.stats.anova_lm(model, typ=2)
print(aov_table)
Nice. According to the results of your two-way ANOVA, both of the factors, Sex and Team, have a significant effect on Weight. However, no significant interactive effect is present.


<script.py> output:
                    sum_sq     df           F        PR(>F)
    Sex       11975.530932    1.0  159.038723  7.512939e-33
    Team      12274.160018    1.0  163.004609  1.506805e-33
    Sex:Team    107.335230    1.0    1.425445  2.329344e-01
    Residual  50149.444322  666.0         NaN           NaN
------------------------------------------------------------------------------------------------------------------------------------

3
Sample size, Power analysis, and Effect size

In this chapter, you will focus on ways to avoid drawing false conclusions, whether false positives (type I errors) or false negatives (type II errors). Central to avoiding false negatives is understanding the interplay between sample size, power analysis, and effect size.
----------------------------------------------------------------------------------------------------------------------------------------

Bonferroni correction
Improved nutrition and healthcare has lead to increased human heights in most societies over the past century. But is this trend also reflected amongst elite athletes? To examine this, we'll be looking at another slice from our Olympic dataset and performing multiple tests.

You have been provided with the athletes dataset containing information about American male Olympic athletes from three years: 1924, 1952, and 2016. You will perform two-sample t-tests to compare the three timepoints, seen in boxplots. Between which times do significant differences exist? As you'll be performing multiple non-independent tests, you will need to perform Bonferroni correction on the results. statsmodels, scipy.stats, and pandas have been loaded for you as sm, stats, and pd.

Boxplots of athlete heights from three chosen years

Instructions
100 XP
Perform three two-sample t-tests, comparing each possible pair of years.
Create an array containing the p-values from your three t-tests and print it.
Perform a Bonferroni correction on the p-values and print the result.

# Perform t-tests 
t_result_1924v2016= stats.ttest_ind(athletes[athletes.Year == "1924"].Height,athletes[athletes.Year == "2016"].Height)
t_result_1952v2016= stats.ttest_ind(athletes[athletes.Year == "1952"].Height,athletes[athletes.Year == "2016"].Height)
t_result_1924v1952= stats.ttest_ind(athletes[athletes.Year == "1924"].Height,athletes[athletes.Year == "1952"].Height)

# Create array of p-values
pvals_array = [t_result_1924v2016[1],t_result_1952v2016[1],t_result_1924v1952[1]]
print(pvals_array)

# Perform Bonferroni correction
adjustedvalues = sm.stats.multitest.multipletests(pvals_array, alpha=0.05, method='b')
print(adjustedvalues)


<script.py> output:
    [2.0995273280295586e-16, 4.484419167217926e-05, 0.00013562429334889784]
    (array([ True,  True,  True]), array([6.29858198e-16, 1.34532575e-04, 4.06872880e-04]), 0.016952427508441503, 0.016666666666666666)

Nice. See how the Bonferroni correction affects your values? This correction method is quite conservative.
----------------------------------------------------------------------------------------------------------------------------------------
Šídák correction
We're looking at how the Height of Olympic athletes from the athletes dataset has changed over time. In this exercise, we're considering three events, the 100 meter, the High Jump, and the Marathon. You'll be examining the correlation between Height and Year separately for each Event. As you did before, you'll need to correct for multiple hypothesis tests, but, since these tests are independent, you can use the less-strict Šídák correction.

Scatter plots of athlete heights in relation to year for three Olympic events

Instructions
100 XP
Perform three Pearson correlations, examining the correlation between Height and Year for each of the three Events.
Create an array containing the p-values from your three tests and print it.

Perform a Šídák correction on the p-values and print the result.

# Perform Pearson correlations
pearson100 = stats.pearsonr(athletes[athletes.Event == "100 meters"].Height, athletes[athletes.Event == "100 meters"].Year)
pearsonHigh = stats.pearsonr(athletes[athletes.Event == "High Jump"].Height, athletes[athletes.Event == "High Jump"].Year)
pearsonMara = stats.pearsonr(athletes[athletes.Event == "Marathon"].Height, athletes[athletes.Event == "Marathon"].Year)

# Create array of p-values
pvals_array = [pearson100[1],pearsonHigh[1],pearsonMara[1]]
print(pvals_array)

# Perform Šídák correction
adjustedvalues=  sm.stats.multitest.multipletests(pvals_array, alpha=0.05, method='s')
print(adjustedvalues)
----------------------------------------------------------------------------------------------------------------------------------------
Exploring sample size
Now we'll explore the effect of sample size on the results of statistical tests. Here, we'll be comparing the Weight of American Athletics and Swimming competitors in the athletes dataset. The boxplots show the difference between these two groups.

Boxplots of body weights of Olympic athletes from two sports

Using a defined seed and varying sample sizes, you will perform t-tests comparing the Weight of samples from both Sports. random, scipy.stats, and pandas have been loaded for you as random, stats, and pd.

Instructions 1/3
35 XP
Instructions 1/3
35 XP
1
Create a subset using the provided seed for 1000 samples; perform and print a t-test to compare Weight between Sports.

# Create sample with defined random seed and perform t-test
subset = athletes.sample(n=1000, random_state= 1007)
print(stats.ttest_ind(subset[subset.Sport == "Athletics"].Weight, subset[subset.Sport == "Swimming"].Weight))

<script.py> output:
    Ttest_indResult(statistic=-4.5957029380768635, pvalue=4.865150456250805e-06)
    
    
Change the sample size to 200, repeat the t-test to compare Weight between Sports, and print the results.

# Create sample with defined random seed and perform t-test
subset = athletes.sample(n=200,random_state= 1007)
print(stats.ttest_ind(subset[subset.Sport=="Athletics"].Weight, subset[subset.Sport=="Swimming"].Weight))

<script.py> output:
    Ttest_indResult(statistic=-2.015353197866729, pvalue=0.045219679216043834)
    
    
    
Create a subset using the same seed for 50 samples; perform and print a t-test to compare Weight between Sports.

# Create sample with defined random seed and perform t-test
subset = athletes.sample(n=50, random_state= 1007)
print(stats.ttest_ind(subset[subset.Sport == "Athletics"].Weight, 
                      subset[subset.Sport == "Swimming"].Weight))
		      
		      
		      
Great! Look how smaller samples affected your p-value. With sample sizes of 1000, 200 and 50, you got p-values of 0.0000045, 0.045 and 0.68, respectively. The smallest sample size didn't give a significant result. Now you see how much difference sample size can make.		      
----------------------------------------------------------------------------------------------------------------------------------------

Sample size for a t-test
Now that we've seen the importance of sample size, let's have another look at the same athletes dataset and see if we can determine the sample size we would need to get a significant result.

Boxplots of body weights of Olympic athletes from two sports

The boxplot shows the difference in body weight between sports, using all 2830 rows from the athletes dataset. The difference between the groups looks quite small. Determine the sample size we would need to have an 80% chance of detecting a small (0.4) difference between these two samples. statsmodels.stats.power and pandas have been loaded for you as pwr and pd.

Instructions
100 XP
Set effect, power, and alpha to 0.4, 0.8 and 0.05, respectively.
Calculate the ratio using the relative lengths of the series for swimming (swimmercount) compared to athletics (athletecount) competitors.
Initialize the analysis, solve the equation for sample size, and print the output.

# Set parameters
effect = 0.4
power = 0.8
alpha = 0.05

# Calculate ratio
swimmercount = float(len(athletes[athletes.Sport == "Swimming"].index))
athletecount = float(len(athletes[athletes.Sport == "Athletics"].index))
ratio = swimmercount/athletecount

# Initialize analysis and calculate sample size
analysis = pwr.TTestIndPower()
ssresult = analysis.solve_power(effect_size=effect, power=power, alpha=alpha, nobs1=None, ratio=ratio)
print(ssresult)

----------------------------------------------------------------------------------------------------------------------------------------
4
Testing Normality: Parametric and Non-parametric Tests
0%
In this final chapter, you will examine the assumptions underlying statistical tests and learn about how that influences your experimental design. This will include learning whether a variable follows a normal distribution and when you should use non-parametric statistical tests like the Wilcoxon rank-sum test and the Spearman correlation test.
